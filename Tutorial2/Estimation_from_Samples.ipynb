{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92971b6e",
   "metadata": {},
   "source": [
    "---\n",
    "title: Estimation from Samples\n",
    "math: \n",
    "    '\\abs': '\\left\\lvert #1 \\right\\rvert' \n",
    "    '\\norm': '\\left\\lvert #1 \\right\\rvert' \n",
    "    '\\Set': '\\left\\{ #1 \\right\\}'\n",
    "    '\\mc': '\\mathcal{#1}'\n",
    "    '\\M': '\\boldsymbol{#1}'\n",
    "    '\\R': '\\mathsf{#1}'\n",
    "    '\\RM': '\\boldsymbol{\\mathsf{#1}}'\n",
    "    '\\op': '\\operatorname{#1}'\n",
    "    '\\E': '\\op{E}'\n",
    "    '\\d': '\\mathrm{\\mathstrut d}'\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2d9c4b",
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# Execute this cell first to import the required libraries\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "%matplotlib widget\n",
    "if not os.getenv(\n",
    "    \"NBGRADER_EXECUTION\"\n",
    "):\n",
    "    %reload_ext jupyter_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438aa1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ai\n",
    "Add comments to the first code cell to explain the code concisely:\n",
    "--\n",
    "{In[1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2679e2e0",
   "metadata": {},
   "source": [
    "This notebook will demonstrate the fundamental concepts of {term}`bias` and {term}`consistency` using Monte Carlo simulations.[^mc] \n",
    "\n",
    "[^mc]: See an [introduction to Monte Carlo Simulation](https://ccha23.github.io/cs1302i24a/numerical-analysis#monte-carlo-simulation)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bbd856",
   "metadata": {},
   "source": [
    "::::{tip} How to add math to notebooks?\n",
    "\n",
    "To include mathematical expressions in your solution, refer to the [MyST guide](https://mystmd.org/guide/math). You may organize the mathematical contents into definitions ([](#def:coin-flip)), theorems ([](#pro:confidence-interval)), and proofs ([](#prf:consistency)) using the proof directives as explained [here](https://mystmd.org/guide/proofs-and-theorems). \n",
    "\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f589fa51",
   "metadata": {},
   "source": [
    "## Estimation Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa60562",
   "metadata": {},
   "source": [
    "Given a coin that is possibly biased, i.e., a coin toss has an unknown probability $p\\in [0,1]$ of landing heads, how to estimate $p$ based on a sequence of coin tosses? More precisely:\n",
    "\n",
    "\n",
    "::::{prf:definition} estimating the chance of head\n",
    ":label: def:coin-flip\n",
    "\n",
    "Consider a random process denoted by a generic random variable $\\R{Z}\\sim \\operatorname{Bern}(p)$ that indicates whether the outcome of a coin flip is a head or not, i.e.,\n",
    "\n",
    "$$\n",
    "\\R{Z} := \\begin{cases}\n",
    "1 & \\text{if a head comes up,}\\\\\n",
    "0 & \\text{if a tail comes up.}\n",
    "\\end{cases}\n",
    "$$ (eq:indicator)\n",
    "\n",
    "The goal is to estimate the expectation of $\\R{Z}$,\n",
    "\n",
    "$$\n",
    "E[\\R{Z}] = P[\\R{Z}=1] = p\n",
    "$$ (eq:expectation)\n",
    "\n",
    "given an i.i.d. sample of $\\R{Z}$ of size $n$, denoted as\n",
    "\n",
    "$$\n",
    "\\R{Z}^n:=(\\R{Z}_1,\\dots,\\R{Z}_n) \\text{ with }\n",
    "P_{\\R{Z}^n|\\R{Z}} = P_{\\R{Z}}^n.\n",
    "$$ (eq:sample)\n",
    "\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b57a44",
   "metadata": {},
   "source": [
    "A convenient way to obtain the i.i.d. sample is to simulate the random process using a {term}`pseudorandom number generator`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece11c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize random number generator with a seed\n",
    "rng = np.random.default_rng(seed=0)\n",
    "\n",
    "# Generate the probability of head randomly\n",
    "p = rng.random()\n",
    "\n",
    "# Set the number of coin tosses we want to simulate\n",
    "n = 5000\n",
    "\n",
    "# Use the choice function to simulate n coin tosses,\n",
    "# with \"H\" (heads) and \"T\" (tails) as possible outcomes,\n",
    "# and the probability of heads and tails given by p and 1-p, respectively.\n",
    "coin_tosses = rng.choice([\"H\", \"T\"], size=n, p=[p, 1 - p])\n",
    "coin_tosses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31041394",
   "metadata": {},
   "source": [
    "The above code uses **NumPy**,[^np] which is a popular python package for efficient computation on high-dimensional arrays:\n",
    "- `default_rng` returns a random number generator. Setting the `seed` ensures reproducibility of the results.\n",
    "- `choice` is a method of the generator to generates a random sample from a given list of possible outcomes.\n",
    "- `p` keeps the value of the unknown probability $p$, which is uniformly randomly picked from the unit interval $[0,1)$.\n",
    "- `coin_tosses` is a [NumPy](https://numpy.org/) array of `\"H\"` and `\"T\"`, which denote the outcomes \"head\" and \"tail\" respectively.\n",
    "\n",
    "[^np]:  See the [official documentation](https://numpy.org/) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1793dc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ai\n",
    "Why should we set a random seed in Monte-Carlo simulation? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822487d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ai\n",
    "What is a NumPy array and why should we use it to store and process\n",
    "sequences of numbers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd61852f",
   "metadata": {},
   "source": [
    "To obtain the i.i.d. sample $\\R{Z}^n$ in [](#eq:sample), simply run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2bdd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "coin_tosses == \"H\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfbb9c1",
   "metadata": {},
   "source": [
    "which gives a list of `1` (`True`) and `0` (`False`) obtained by element-wise equality comparisons with `\"H\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778734ba",
   "metadata": {},
   "source": [
    "## M-Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0129ca95",
   "metadata": {},
   "source": [
    "A natural way to estimate $p$ is the M-estimate (sample average estimate)\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\R{\\hat{p}} &:= \\frac1n \\sum_{i=0}^{n-1} \\R{Z}_i\\\\\n",
    "&= \\frac{\\abs{\\{1\\leq i\\leq n| \\R{Z}_i=1\\}} }{n},\n",
    "\\end{align}\n",
    "$$ (eq:sample-avg)\n",
    "\n",
    "which is the fraction of the coin tosses coming up heads. The observed distribution $(\\R{\\hat{p}}, 1-\\R{\\hat{p}})$ of heads and tails is called {term}`empirical distribution`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8486dfe",
   "metadata": {},
   "source": [
    "The estimate can be implemented as follows using the method `mean` of a `numpy` array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3858eb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(coin_tosses == \"H\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9705e9",
   "metadata": {},
   "source": [
    "Is the estimate good? The following is one desirable property:\n",
    "\n",
    "::::{prf:definition} unbiased estimate\n",
    ":label: def:unbiased\n",
    "\n",
    "An estimator $f:Z^n\\to \\mathbb{R}$ of $E[\\R{Z}]$ from a random sample $\\R{Z}^n$ is said to be *unbiased* iff\n",
    "\n",
    "$$\n",
    "E[f(\\R{Z}^n)] = E[\\R{Z}],\n",
    "$$ (eq:unbiased)\n",
    "\n",
    "namely, the estimate is correct in expectation.\n",
    "\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7926d96",
   "metadata": {},
   "source": [
    "::::{exercise}\n",
    ":label: ex:unbiased\n",
    "\n",
    "The following show that the M-estimate [](#eq:sample-avg) is an unbiased estimate, i.e., [](#eq:unbiased) holds for $f(\\R{Z}^n)=\\R{\\hat{p}}$.\n",
    "\n",
    "\n",
    ":::{prf:proof} Unbiasedness\n",
    ":nonumber:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "E[\\R{\\hat{p}}] &= E\\left[\\frac1n \\sum_{i=0}^{n-1} \\R{Z}_i \\right]\\\\\n",
    "&= \\frac1n \\sum_{i=0}^{n-1} \\underbrace{E[\\R{Z}_i]}_{=p} && \\text{by ???}\\\\\n",
    "&= p.\n",
    "\\end{aligned}\n",
    "$$ (eq:unbiased:sample-avg)\n",
    "\n",
    ":::\n",
    "\n",
    "What is the missing reasoning?\n",
    "\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddc03b8",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2ca3b7658975f190d06da1524e2fba19",
     "grade": true,
     "grade_id": "linearity",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": [
     "remove-output"
    ]
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f76e94a",
   "metadata": {},
   "source": [
    "An unbiased estimate, while correct in expectation, can be far away from the ground truth especially when the variance is large. It is desirable for an estimate to be nearly correct with high probability, which can be stated more formally below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d297d4da",
   "metadata": {},
   "source": [
    "::::{prf:definition} consistency\n",
    "\n",
    "An estimator $f:Z^n\\to \\mathbb{R}$ of $E[\\R{Z}]$ from a random sample $\\R{Z}^n$ is said to be *consistent* iff\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\lim_{n\\to\\infty} P[\\abs{f(\\R{Z}^n)- E[\\R{Z}]}\\leq \\epsilon]=1 && \\text{for all $\\epsilon>0$},\n",
    "\\end{align}\n",
    "$$ (eq:consistent)\n",
    "\n",
    "namely, the estimate converge to the ground truth in probability.[^as-convergence]\n",
    "\n",
    "::::\n",
    "\n",
    "[^as-convergence]: Indeed, one can consider the stronger notion of convergence\n",
    "$$\n",
    "P\\left[\\lim_{n\\to \\infty} f(\\R{Z}^n) = E[\\R{Z}]\\right] = 1,\n",
    "$$\n",
    "i.e., the estimate converge to the ground truth almost surely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d20db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ai\n",
    "Explain in simple words in one paragraph the different between convergence \n",
    "in probability and almost sure convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c61af8",
   "metadata": {},
   "source": [
    "::::{exercise}\n",
    ":label: ex:consistent\n",
    "\n",
    "The M-estimate [](#eq:sample-avg) is a consistent estimate, i.e., [](#eq:consistent) holds for $f(\\R{Z}^n)=\\R{\\hat{p}}$, due to the [law of large number (LLN)](https://en.wikipedia.org/wiki/Law_of_large_numbers).\n",
    "\n",
    "\n",
    ":::{prf:proof} Consistency\n",
    ":label: prf:consistency\n",
    "\n",
    "It follows from [](#eq:unbiased:sample-avg) that\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P\\left[ \\abs{\\R{\\hat{p}}-E[\\R{Z}]}>\\epsilon \\right] &\\leq \\frac{\\sigma^2}{\\epsilon^2} && \\text{by ???}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "for all $\\epsilon>0$, where\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\sigma^2 &:=\\operatorname{Var}[\\R{\\hat{p}}]\\\\\n",
    "&= \\operatorname{Var}\\left[\\frac1{n} \\sum_{i=0}^{n-1} \\R{Z}_i\\right]\\\\\n",
    "&= \\frac1{n^2} \\operatorname{Var}\\left[\\sum_{i=0}^{n-1} \\R{Z}_i\\right]\\\\\n",
    "&=\\frac1{n^2} \\sum_{i=1}^n \\underbrace{\\operatorname{Var}[\\R{Z}_i]}_{=p(1-p)} && \\text{by ???}\\\\\n",
    "&=\\frac{p(1-p)}{n}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "which goes to $0$ as desired when $n\\to \\infty$.\n",
    "\n",
    ":::\n",
    "\n",
    "What are in the missing reasonings?\n",
    "\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9612ec",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d655a8850dcdfbc8e9f8d0fffa537d54",
     "grade": true,
     "grade_id": "indep",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": [
     "remove-output"
    ]
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34539ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ai\n",
    "Explain in one paragraph how the LLN can be used to show that \n",
    "an M-estimate is consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57088e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ai\n",
    "Explain in one paragraph what Chernoff bound is and how to use it to prove the LLN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10a5317",
   "metadata": {},
   "source": [
    "To illustrate consistency, the following code generates and plots the estimate $\\R{\\hat{p}}$ for different sample size $n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d97850",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 5000\n",
    "n = np.arange(1, size + 1)\n",
    "phat = (coin_tosses == \"H\").cumsum() / n  # use first n tosses to estimate\n",
    "sigma = (p * (1 - p) / n) ** 0.5  # true standard deviations of the estimates\n",
    "\n",
    "# Create Figure 1, or clear it if it exists\n",
    "plt.figure(1, clear=True)\n",
    "\n",
    "# plot the ground truth p\n",
    "plt.axhline(p, color=\"red\", label=r\"$p$\")\n",
    "\n",
    "# fill the region 2 sigma away from p\n",
    "plt.fill_between(\n",
    "    n, p - 2 * sigma, p + 2 * sigma, color=\"red\", alpha=0.2, label=r\"$p\\pm 2\\sigma$\"\n",
    ")\n",
    "\n",
    "# plot the estimates phat\n",
    "plt.plot(\n",
    "    n,\n",
    "    phat,\n",
    "    marker=\".\",\n",
    "    color=\"blue\",\n",
    "    linestyle=\"\",\n",
    "    markersize=1,\n",
    "    label=r\"$\\hat{\\mathsf{p}}$\",\n",
    ")\n",
    "\n",
    "# configure the plot\n",
    "plt.ylim([0, 1])\n",
    "plt.xlim([0, n.size])\n",
    "plt.title(r\"Plot of ${\\hat{p}}$ vs sample size\")\n",
    "plt.xlabel(\"sample size\")\n",
    "plt.ylabel(\"probability\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea0860f",
   "metadata": {},
   "source": [
    "For a consistent estimator, it is expected that the estimates (blue dots) converge to the ground truth (red line) as the sample size increases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5f0389",
   "metadata": {},
   "source": [
    "In addition, observe that the estimates mostly fall within $2$ standard deviation away from the ground truth, i.e., the convergence rate follows the rate of drop in the standard deviation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4321766e",
   "metadata": {},
   "source": [
    "::::{prf:proposition} confidence interval estimate\n",
    ":label: pro:confidence-interval\n",
    "\n",
    "The sample average estimates falls within $2$ standard deviation away from the ground truth over $95\\%$ of the time, i.e.,\n",
    "\n",
    "$$\n",
    "P\\left[\\R{\\hat{p}}\\in [p-2\\sigma, p+2\\sigma]\\right] \\geq 0.95.\n",
    "$$\n",
    "\n",
    "The interval $[\\R{\\hat{p}}-2\\sigma, \\R{\\hat{p}}+2\\sigma]$ is referred to as the $95\\%$-confidence interval estimate of $p$, with a confidence level of $95\\%$.\n",
    "\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcedb8a0",
   "metadata": {},
   "source": [
    "The proof uses the [central limit theorem (CLT)](https://en.wikipedia.org/wiki/Central_limit_theorem): As $n$ goes to $\\infty$, the estimate almost surely has the gaussian/normal distribution plotted as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91536275",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(num=2, clear=True)\n",
    "\n",
    "# plot the stardard normal distribution\n",
    "x = np.linspace(-4, 4, 8 * 10 + 1)\n",
    "plt.plot(x, norm.pdf(x), color=\"red\", label=r\"$\\frac{1}{\\sqrt{2\\pi}}e^{-x^2/2}$\")\n",
    "\n",
    "# Fill the area under curve within certain number of standard deviations from the mean\n",
    "for i in range(3, 0, -1):\n",
    "    plt.fill_between(\n",
    "        x,\n",
    "        norm.pdf(x),\n",
    "        alpha=2 ** (-i),\n",
    "        color=\"blue\",\n",
    "        label=rf\"$\\Pr(|\\hat{{p}}-p|\\leq{i}\\sigma)\\approx {(norm.cdf(i)- norm.cdf(-i))*100:.3g}\\%$\",\n",
    "        where=(abs(x) <= i),\n",
    "    )\n",
    "\n",
    "# Label the plot\n",
    "plt.title(\n",
    "    r\"Standard normal distribution for $\\frac{{\\hat{p}}-{p}}{\\sigma}$ as $n\\to \\infty$\"\n",
    ")\n",
    "plt.xlabel(r\"x\")\n",
    "plt.ylabel(r\"probability density\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d128e03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ai\n",
    "Give a scenario where LLN holds but CLT does not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880fcc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ai\n",
    "Explain in simple words how to prove and understand the CLT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddd5835",
   "metadata": {},
   "source": [
    ":::::{seealso} What are LLN and CLT?\n",
    ":class: dropdown\n",
    "\n",
    "See the following video by [Prof. Robert Gallager](https://en.wikipedia.org/wiki/Robert_G._Gallager):\n",
    "\n",
    "::::{card}\n",
    ":header: [Open in new tab](https://www.youtube.com/embed/k0UZNZwPO8Q?si=VcQtGu935KotF8qg)\n",
    ":::{iframe} https://www.youtube.com/embed/k0UZNZwPO8Q?si=VcQtGu935KotF8qg\n",
    ":width: 100%\n",
    ":::\n",
    "::::\n",
    "\n",
    ":::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4feeae8e",
   "metadata": {},
   "source": [
    "## A Coin Tossing Game"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf598c4",
   "metadata": {},
   "source": [
    "To understand the concept of bias in estimation, imagine playing the coin-tossing game:\n",
    "\n",
    "- You win if a coin toss comes up head.\n",
    "- You get to choose 1 out of the $m$ coins $i\\in \\{0,\\dots,m-1\\}$ with unknown probability $p_i$ of coming up head.\n",
    "- You can flip each coin $n$ times before making your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d481da",
   "metadata": {},
   "source": [
    "**How to play the game?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031224b5",
   "metadata": {},
   "source": [
    "A particular strategy for playing the game is to \n",
    "1. estimate the chance $p_i$ by the empirical probability $\\R{\\hat{p}}_i$ for each coin $i$, and\n",
    "1. select the coin (with ties broken arbitrarily)\n",
    "\n",
    "  $$\n",
    "  \\R{J} := \\arg\\max_i \\R{\\hat{p}}_i.\n",
    "  $$\n",
    "\n",
    "It is easy to see that the chance of winning by the given strategy is $E[p_{\\R{J}}]$. Is the strategy optimal? Can a player evaluate or estimate the chance of winning without knowing $p_i$'s? Is the following a good estimate:\n",
    "\n",
    "$$\n",
    "\\R{\\hat{p}}_{\\R{J}} = \\max_i\\R{\\hat{p}}_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07de2f0",
   "metadata": {},
   "source": [
    "::::{important} How is the strategy related to data-mining?\n",
    "\n",
    "Suppose $\\R{\\hat{p}}_i$ is the empirical accuracy of the classifier $f_i$. A common model selection strategy is to \n",
    "- choose the classifier $\\R{J}$ defined above that has the highest empirical accuracy, and\n",
    "- estimate its performance by $\\R{\\hat{p}}_{\\R{J}}$.\n",
    "\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff25244",
   "metadata": {},
   "source": [
    "**How to evaluate the estimate?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa56ce8f",
   "metadata": {},
   "source": [
    "Consider the simple case $n=1$, $m=2$, and $p_0=p_1=0.5$. We have the following four equally likely events:\n",
    "\n",
    "$$\n",
    "\\begin{array}{ccc} \\R{\\hat{p}}_0 & \\R{\\hat{p}}_1 & \\max_i \\R{\\hat{p}}_i \\\\\\hline\n",
    "0 & 0 & 0\\\\ \n",
    "0 & 1 & 1\\\\ \n",
    "1 & 0 & 1\\\\ \n",
    "1 & 1 & 1\\\\ \n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdf9fe3",
   "metadata": {},
   "source": [
    "::::{exercise}\n",
    ":label: ex:n=1\n",
    "\n",
    "For the above simple case, compute $E[p_{\\R{J}}]$ and $E[\\max_i\\R{\\hat{p}}_i]$. Is $\\max_i\\R{\\hat{p}}_i$ an unbiased estimate of $E[p_{\\R{J}}]$?\n",
    "\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a737c415",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ed2a7719b52a80e7501765e607b7ee04",
     "grade": true,
     "grade_id": "n1",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ea6760",
   "metadata": {},
   "source": [
    "Instead of carrying out the exact analysis, which involves [order statistics][os], we will conduct the [Monte-Carlo simulation][MC] of the coin tossing game. The simulation can be verified by hand-calculating the closed-form solution for $n=1$, $m=2$, and $p_0=p_1=0.5$.\n",
    "\n",
    "[MC]: https://www.cs.cityu.edu.hk/~ccha23/cs1302book/Lecture9/Monte%20Carlo%20Simulation%20and%20Linear%20Algebra.html\n",
    "[os]: https://en.wikipedia.org/wiki/Order_statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029cb8db",
   "metadata": {},
   "source": [
    "The following initializes the list `p_list` of probabilities of head for different coins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23abd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 2\n",
    "p_list = np.array([0.4] * (m - 1) + [0.6])\n",
    "# To generate the probability randomly instead, use\n",
    "# p_list = rng.random(m)\n",
    "p_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b50138",
   "metadata": {},
   "source": [
    "Instead of generating a sequence of coin tosses, we will simulate $\\R{\\hat{p}}_i$ directly using the binomial distribution since\n",
    "\n",
    "$$\n",
    "n\\R{\\hat{p}}_i\\sim \\operatorname{Binomial}(n,p_i).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6614e462",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 10\n",
    "n = np.arange(1, size + 1)\n",
    "k = 100000\n",
    "phat = rng.binomial(\n",
    "    n.reshape(-1, 1, 1), p_list.reshape(1, -1, 1), (size, m, k)\n",
    ") / n.reshape(-1, 1, 1)\n",
    "max_phat = phat.max(axis=1)\n",
    "max_phat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71ad81c",
   "metadata": {},
   "source": [
    "`max_phat` is a 2-dimensional array of samples of $\\max_{i}\\R{\\hat{p}}_i$:\n",
    "- The first axis indexes samples obtained from different number of tosses.\n",
    "- The second axis indexes `k` independent samples for the same number of tosses.\n",
    "\n",
    "The `k` independent samples can be used to approximates $E[\\max_{i}\\R{\\hat{p}}_i]$ as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1545d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "E_max_phat = max_phat.mean(axis=-1)\n",
    "E_max_phat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78d4118",
   "metadata": {},
   "source": [
    "Similarly, the winning probability can be approximated as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fe8220",
   "metadata": {},
   "outputs": [],
   "source": [
    "win_prob = p_list[phat.argmax(axis=1)].mean(axis=-1)\n",
    "win_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17b2058",
   "metadata": {},
   "source": [
    "The following plots compare the probabilities as a function of $n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a56b642",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 726
    },
    "colab_type": "code",
    "id": "eEpEkzHe_Nri",
    "outputId": "e54a77b2-d0e3-4f85-ed8d-8743de445ddb"
   },
   "outputs": [],
   "source": [
    "plt.figure(3, clear=True)\n",
    "plt.axhline(p_list.max(), color=\"red\", label=r\"$\\max_i p_i$\")\n",
    "plt.plot(\n",
    "    n,\n",
    "    E_max_phat,\n",
    "    linestyle=\"--\",\n",
    "    marker=\".\",\n",
    "    color=\"blue\",\n",
    "    markersize=10,\n",
    "    label=r\"$E[\\max_i{\\hat{p}}_i]$\",\n",
    ")\n",
    "plt.plot(\n",
    "    n,\n",
    "    win_prob,\n",
    "    linestyle=\":\",\n",
    "    marker=\"x\",\n",
    "    color=\"green\",\n",
    "    markersize=10,\n",
    "    label=\"winning probability\",\n",
    ")\n",
    "\n",
    "plt.ylim([0, 1])\n",
    "plt.xlim([n[0], n[-1]])\n",
    "plt.title(r\"Plot of $E[\\max_i{\\hat{p}}_i]$ vs $n$\")\n",
    "plt.xlabel(\"$n$\")\n",
    "plt.ylabel(\"probability\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeca9fae",
   "metadata": {},
   "source": [
    "::::{exercise}\n",
    ":label: ex:max_p\n",
    "\n",
    "Compare the chance of winning with $\\max_i p_i$ more generally for different $p_i$'s.\n",
    "\n",
    ":::{hint}\n",
    ":class: dropdown\n",
    "\n",
    "Change `p_list` to explore the non-uniform cases where $p_i$'s may not be equal. Be careful about the deterministic case where $p_i\\in \\Set{0,1}$ for all $i$.\n",
    "\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fdd6f8",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "16194c7ed1e6f65fa46abc3be3876082",
     "grade": true,
     "grade_id": "winprob_vs_max_p",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": [
     "remove-output"
    ]
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960bb0e1",
   "metadata": {},
   "source": [
    "::::{exercise}\n",
    ":label: ex:max_phat:bias\n",
    " Compare the chance of winning with $E[\\max_i \\R{\\hat{p}}_i]$. Is $\\max_i \\R{\\hat{p}}_i$ a biased estimate? If so, is it overly optimistic, i.e., has an expectation larger than the chance of winning?\n",
    "\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a018b0",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "220bd6f1ef3afd28714d6ac6b247e122",
     "grade": true,
     "grade_id": "winprob_vs_max_phat",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": [
     "remove-output"
    ]
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01141d04",
   "metadata": {},
   "source": [
    "::::{exercise} \n",
    ":label: ex:max_phat:consistency\n",
    "\n",
    "Is $\\max_i \\R{\\hat{p}}_i$ a consistent estimate of the chance of winning?\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2cdae3",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3237f6317457954f58b14d1e2702de5a",
     "grade": true,
     "grade_id": "consistency",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": [
     "remove-output"
    ]
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3356e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ai\n",
    "State in simple words the uniform LLM and how it differs from the usual LLM.\n",
    "Explain what makes uniform convergence possible and why it can be applied to\n",
    "data mining and machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef735fc1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "## Glossary\n",
    "\n",
    ":::::{admonition}\n",
    ":class: dropdown\n",
    "\n",
    "::::{glossary}\n",
    "\n",
    "bias\n",
    ": The discrepancy between the expected estimate from an estimator and the ground truth of the unknown being estimated.\n",
    "\n",
    "consistency\n",
    ": The property of an estimator whereby a sequence of estimates converges in probability to the ground truth as the sample size increases.\n",
    "\n",
    "empirical distribution\n",
    ": The frequencies of the different values observed in a dataset.\n",
    "\n",
    "pseudorandom number generator\n",
    ": A algorithm to produce a seemingly random but actually deterministic sequence of numbers.\n",
    "\n",
    "::::\n",
    "\n",
    ":::::"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "default_lexer": "ipython3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
